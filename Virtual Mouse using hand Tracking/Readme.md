### Project Name:- Virtual mouse using hand tracking

### Aim:- The aim is to control cursor movement and actions virtually using hand tracking and gestures

#### Project summary:- 
The project is about controlling the cursor movement and actions using hand tracking and finger gestures. The cursor's position will be only controlled if the hand is detected inside the boundary screen. We will use openCV and Mediapipe for hand detection and tracking, Numpy to perform calculations related to cursor location, Wx-Python to capture screen size and Pynput to integrate finger movement with cursor.

#### Tech Stack:-
Python
OpenCV
Mediapipe
Numpy
Pynput
Wx-Python

### How Mediapipe works
MediaPipe Hands is a high-fidelity hand and finger tracking solution. It employs machine learning (ML) to infer 21 3D landmarks of a hand from just a single frame. Whereas current state-of-the-art approaches rely primarily on powerful desktop environments for inference, our method achieves real-time performance on a mobile phone, and even scales to multiple hands. We hope that providing this hand perception functionality to the wider research and development community will result in an emergence of creative use cases, stimulating new applications and new research avenues.<br>

![Hand landmarks](https://google.github.io/mediapipe/images/mobile/hand_landmarks.png)<br>
![Hand tracking in different postures](https://google.github.io/mediapipe/images/mobile/hand_crops.png)<br>

#### Group Members:-
<br> Dharmik Vara</br>
<br> Hemaraj Dhakal</br>
<br> Simran Yadav</br>
<br> Satvika Koti</br>
<br> Sai poornima</br>
<br> Sakalya Mitra</br>

### Mentor:-
<br>Miss Surbhi</br>
<br>Divya Sri</br>

### Image

![image](https://user-images.githubusercontent.com/65659902/124559895-eb89d100-de5b-11eb-83a5-ae23c3c9da3d.png)


